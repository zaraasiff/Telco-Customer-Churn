# -*- coding: utf-8 -*-
"""untitled1.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ei4XM0kVf0k8iyMcme3DlUZc-JOL-e5T
"""

# basics
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ML
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

# models
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

# imbalance
from imblearn.over_sampling import SMOTE

# interpretability
import shap

sns.set(style="whitegrid")

from google.colab import files
print("Please upload 'WA_Fn-UseC_-Telco-Customer-Churn.csv.")
uploaded = files.upload()

csv_fname = list(uploaded.keys())[0]
df = pd.read_csv(csv_fname)


df.head()

df.info()
df.isnull().sum()
df['Churn'].value_counts(normalize=True)  # target balance

# churn counts
sns.countplot(x='Churn', data=df)
plt.title("Churn distribution")
plt.show()

# tenure distribution
sns.histplot(df['tenure'], bins=30)
plt.title("Tenure distribution")
plt.show()

# categorical distribution example
sns.countplot(y='Contract', hue='Churn', data=df)
plt.title("Churn by contract type")
plt.show()

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE

# 1) Load dataset
df = pd.read_csv(csv_fname)

# 2) Missing values
print("Missing values:\n", df.isnull().sum())
df = df.dropna()   # simple: drop missing rows (ya fill bhi kar sakti ho)

# 3) Encode categorical columns
cat_cols = df.select_dtypes(include="object").columns
encoder = LabelEncoder()
for col in cat_cols:
    df[col] = encoder.fit_transform(df[col])

# 4) Separate features (X) and target (y)
X = df.drop("Churn", axis=1)   # Features
y = df["Churn"]                # Target variable (churn yes/no)

# 5) Scale numeric features
scaler = StandardScaler()
X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# 6) Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print("Before SMOTE:", y.value_counts())
print("After SMOTE:", y_resampled.value_counts())

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 1) Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled
)

# 2) Initialize models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42)
}

# 3) Train and evaluate
results = []

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results.append([name, acc, prec, rec, f1])

# 4) Convert results into DataFrame
results_df = pd.DataFrame(results, columns=["Model", "Accuracy", "Precision", "Recall", "F1-Score"])
print(results_df)

xgb_model = models["XGBoost"]
xgb_model.fit(X_train, y_train)

explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X_test)

# Global summary plot
shap.summary_plot(shap_values, X_test, feature_names=X_test.columns)

## üìå Business Insights

1. Customers with **month-to-month contracts** are much more likely to churn compared to yearly contracts.
2. **Senior citizens and single users** show higher churn rates.
3. Customers with **high monthly charges** but fewer services are more likely to leave.
4. **Automatic payment methods (credit card, bank transfer)** reduce churn likelihood.

### ‚úÖ Recommendations
- Offer discounts or loyalty bonuses for monthly contract users.
- Targeted offers for senior citizens and single customers.
- Bundle high-cost services with promotions to retain customers.
- Promote auto-pay options to improve retention.

import matplotlib.pyplot as plt

# Data
problem = "Predict which customers are likely to churn."
metrics = {"Accuracy": "91%", "Precision": "90%", "Recall": "89%"}
insights = [
    "Short contracts churn more",
    "High monthly charges ‚Üí churn",
    "Tech Support reduces churn"
]
recommendation = "Offer discounts on annual plans & promote Tech Support."

# Compact Card
fig, ax = plt.subplots(figsize=(6,4))
ax.axis("off")
fig.patch.set_facecolor("#f3e8ff")   # light purple background

# Title
plt.text(0.5, 0.92, "üìä Client Insight Card", fontsize=15, fontweight="bold",
         ha="center", color="#4b0082")  # deep purple

# Problem
plt.text(0.02, 0.78, f"üìù {problem}", fontsize=10, color="black", ha="left")

# Metrics block
met_text = " | ".join([f"{k}: {v}" for k,v in metrics.items()])
plt.text(0.5, 0.63, f"üìå {met_text}", fontsize=10, color="#c71585", ha="center")

# Insights block
ins_text = " ‚Ä¢ ".join(insights)
plt.text(0.5, 0.48, f"üîé {ins_text}", fontsize=10, color="black", ha="center", wrap=True)

# Recommendation
plt.text(0.5, 0.32, f"‚úÖ {recommendation}", fontsize=10, color="darkgreen",
         ha="center", wrap=True)

# Footer
plt.text(0.5, 0.12, "#CondantixTech | Python Visualization", fontsize=8,
         color="gray", ha="center")

plt.show()